Emergency department (ED) crowding is a well-known threat to patient safety \cite{Boyle2012} and the documented adverse effects range from a decrease in the work satisfaction of ED staff \cite{Eriksson2018} to increased length of stay \cite{McCarthy2009} and increased mortality \cite{Guttmann2011, Richardson2006, Berg2019, Jo2014}. In contrast to outpatient clinics\footnote{An outpatient clinic is a healthcare facility where patients receive treatment without being admitted to the hospital.} or elective surgery, EDs are unable to adjust the inflow of patients and are thus exposed to both a stochastic incidence of diseases and changes in patientsâ€™ care-seeking behaviour. Moreover, EDs are also usually unable to freely adjust the outflow of patients, since they depend on other health care facilities to organize follow-up care when necessary. The only component that an ED can independently adjust is throughput, which is mostly affected by the quantity \cite{Bucheli2004} and quality \cite{Trotzky2021} of staff. These restrictions lead to repeated crowding which has developed into a global public health crisis \cite{Pearce2023}. Sufficiently accurate forecasts of future service demand would enable proactive administrative decisions aiming to alleviate or even prevent crowding, and has the potential to improve patient outcomes. This rationale has motivated an increasing amount of ED forecasting articles \cite{Gul2018} but for some reason, readily available commercial solutions have not emerged. We believe this to be, at least in part, due to increasingly outdated forecasting methods and lack of relevant multivariable input.

First, a significant amount of ED forecasting literature has focused on the Autoregressive Integrated Moving Average (ARIMA) or its variants \cite{Gul2020}. The tendency to favour an ARIMA model over advanced models is understandable, as it has  up to very recent years repeatedly defended its place over more complex solutions \cite{Zhou2018, Whitt2019, Cheng2021} and has been considered to be \emph{a pinnacle of statistical approach} in time series forecasting in general \cite{Oreshkin2019}. This has been changing rapidly. In 2020, a statistical and deep learning (DL) hybrid proposed by \citet{Smyl2020} outperformed statistical benchmark models in the renowned M4 time series forecasting competition for the first time in the history of the competition \cite{Makridakis2020}. Following this result, several time-series-specific DL architectures have been introduced, such as the Temporal Fusion Transformer (TFT) by \citet{Lim2021}, Neural Expansion Analysis for Interpretable Time Series Forecasting (N-BEATS) by \citet{Oreshkin2019} and DeepAR by \citet{Salinas2020}. In the latest M5 competition in 2022 \cite{Makridakis2022}, all of the best-performing models were pure ML implementations, and out of the five best performing solutions, four utilized a multivariable LightGBM model\cite{Ke2017}. In addition to LightGBM, DeepAR and N-BEATS were highlighted for \emph{showing forecasting potential}. However, these models have not been tested using ED data.

Second, the amount and quality of used input data has been limited. This is an important deficit because of the highly interdependent nature of the ED. As suggested by \citet{Asplin2003}, ED crowding is a sum of three operational components: input (number of arrivals), throughput (length of stay mainly affected by staffing resource) and output (mainly affected by availability of follow-up care beds). A disturbance in one of these components alone can lead to crowding, but the most severe situations are observed when two or more of them are detrimentally affected. This is in line with findings of M5, in which one of the seven key implications of the competition was the importance of exogenous variables \cite{Makridakis2022}. Regardless, ED forecasting input data has repeatedly consisted of simple calendar and weather variables, mounting up to 29 input vectors in total \cite{Whitt2019, Holleman1996, Jiang2018} which leaves a significant proportion of the Asplin's model unaccounted for.

Third, the studies that have suggested the utility of novel input variables, such as website visits \cite{Ekstrom2015}, road traffic flow \cite{Rauch2019} or the emergency department severity index \cite{Cheng2021}, have done so by utilizing only one of them at a time, which runs the risk of an overoptimistic evaluation of variable importance due to the inevitable multicollinearity between them. We thus believe that a data-centric approach with a high number of input variables has the potential to increase predictive accuracy, provide a better understanding of the factors underlying crowding and even inform policies among local health care providers. This is a continuation of our previous work, in which we used simulated annealing and floating search to perform feature selection in order to enhance accuracy when using conventional statistical models \cite{Tuominen2022}.

To conclude, our contributions are as follows: 1) we investigate the performance of state-of-the art ML models in predicting ED occupancy using data spanning over 2 years in a large, combined ED; 2) we use the largest-to-date collection of explanatory variables, containing not only weather and calendar variables, but also the availability of hospital beds, traffic information, local public events, website visits and more, and 3) analyse the proportional importance of these variables when used in conjunction with one another. We show that ML models outperform statistical benchmarks with ED data, reproduce the well-established superiority of LightGBM over other ML models and show that while the explanatory variables enhance the performance of TFT and DeepAR, they do not significantly improve the performance of LightGBM.