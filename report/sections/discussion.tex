In this study, we establish four main findings regarding the use of ML and multivariable input data in forecasting aggregated ED occupancy. We will discuss each of these separately below.

\paragraph{ML models outperform statistical models.} All of the tested ML models outperformed ARIMA benchmark statistically significantly with 8-15\% proportional improvement. In case of N-BEATS, \citet{Oreshkin2019} initially reported a 10\% improvement over statistical models which aligns with the 10\% improvement reported here. For DeepAR, \citet{Salinas2020} reported an average of 15\% improvement over innovation-state space and autoregressive models which is higher than that of the 8\% reported here. This might be due to our relatively small dataset since DeepAR has been designed to work at scale. TFT outperformed other DL models which aligns with both \citet{Lim2021} and \citet{Elsayed2021}. However, it was outperformed by LightGBM, which contradicts \citet{Elsayed2021} who documented TFT to be superior compared to Gradient Boosting Regression Trees (GBDTs), such as LightGBM. Regardless, the breakthrough of ML in time series applications seems to apply to ED data as well.

\paragraph{LightGBM outperforms DL models.} LightGBM was the best performing model both using univariable data and multivariable data. In fact, the univariable $\text{LightGBM}_U$ outperformed multivariable DL models which highlights the performance of the model and undermines the value of multivariable data in this problem setting as discussed in more detail below. The performance of the model is in line with that of the M5 competition \cite{Makridakis2022} and serves to show that ED statistics do not differ in terms of predictability from other time series of interest. The superior performance of tree-based methods over deep learning algorithms in processing tabular data is a recognized phenomenon. This advantage can be linked to two factors: their proficiency in managing uninformative features and their ability to identify and leverage irregular patterns within the target function. Additionally, tree-based methods can exploit the specific structure of the data as it is, even with data whose descriptors are not invariant to transformations, such as rotation, translation and scaling \cite{Grinsztajn2022}.

Regardless, LightGBM makes a good candidate for a model that is not only excellent in performance but also efficient in terms of required computation, since the univariable LightGBM took only 18 minutes to execute on a CPU, which is 86-96\% less than the DL models on a GPU (Appendix \ref{appendix_d}).

\paragraph{Exogenous multivariable data is of limited importance.}
Exogenous variables improved the performance of both TFT and DeepAR by 4\% and 17\% respectively. However, for the top-performing model, LightGBM, there was negligible difference between its multivariable and univariable versions. This indicates that richer models do not necassarily outperform when applied to out-of-sample data. The observed limited importance of exogenous variables, along with LightGBM's superiority, aligns with Occam's Razor. This principle, also termed the principle of parsimony, advocates for the use of models and procedures that that contain all that is necessary for the modeling but nothing more \cite{hawkins2004problem}.

This finding has two practical implications. First, showing that one or more exogenous variables improves performance of a model does not mean that a better univariable model does not exist. It is thus important to prioritize finding high-performing univariable models before extensively collecting all potential exogenous data. Second, from a practical standpoint, it is fortunate that multivariable data does not significantly enhance overall performance in our specific context since implementing a univariable forecasting model is considerably simpler than a multivariable one, particularly when the latter demands continuous data collection from multiple sources.

\paragraph{Lack of prominent covariates.} The intuitive association between follow-up care capacity and increased occupancy was strong and we were expecting an improved performance by including these variables. However, this was not observed, which might be due to a non-trivial amount of missing data in hospital bed variables, as described in section \ref{subsec:data}. The traffic monitoring nodes and their associated time lags appear to have been chosen somewhat arbitrarily. Moreover, the absolute SHAP values of the traffic variables increase in relation to the forecast horizon as can be seen in Figure 4. We attribute this to multicollinearity between the calendar and traffic variables. The traffic variables not only capture the target variableâ€™s weekly seasonality but also provide a marginal, yet beneficial signal. This marginal advantage contrasts with \citet{Rauch2019} who suggested that incorporating these variables could enhance forecasting accuracy by 10-20\%.

We believe that the most important underlying reason for the unexpectedly low value of exogenous covariates is the unstratified sample used in this study. The ED under consideration operates as a Nordic combined facility, serving a highly heterogeneous population that includes medical, surgical, neurological, and psychiatric patients. These patients are further categorized into walk-in versus bed-occupying patients, as well as discharged versus admitted patients. In this study, we combined all patient categories into a single aggregated occupancy metric. This is important because, for example, only 39\% of the presented patients were admitted after initial assessment, meaning that follow-up care capacity had no direct impact on the remaining 61\% of the patients. It is also possible that there are associations between the explanatory variables and some of the subgroups, but these associations are contradicted by other opposite associations between other subgroups. This heterogeneity has to be accounted for in future work.

\subsection{Limitations}
This study is limited by its retrospective single-centre setup, and further work is required to investigate the applicability of our approach to other facilities, preferably in a prospective setting by integrating a production prototype to hospital information infrastructure. In the training set, we observed missing data on hospital beds variables which might obscure their importance. This study focused on an unstratified sample, meaning that pooled occupancy statistics of all treatment rooms were used as the target variable. This is a limitation because occupancies of different treatment spaces might have very different interactions with included explanatory variables. We retrained models each month to limit the computational cost in backtesting phase (even with this restriction, it took 34 hours of computation to produce TFT results, see Appendix \ref{appendix_d}). It is likely that higher retrain frequency (e.g. weekly) would enhance performance even more.